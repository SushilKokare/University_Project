{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushilKokare/AtiNeu_Project/blob/main/ensembleYT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tfjDw7dzuzAP"
      },
      "outputs": [],
      "source": [
        " from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sCNmXQUvHA9",
        "outputId": "33b120c5-2bb1-463a-86ee-d4f31ef03700"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install Augmentor"
      ],
      "metadata": {
        "id": "9b0SxAZMvQeu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import Augmentor"
      ],
      "metadata": {
        "id": "lKbLzDApvi5q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here write augmentiation part"
      ],
      "metadata": {
        "id": "3xXbqQC6v98F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Flatten, Dropout, Input, Average, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization, MaxPooling2D"
      ],
      "metadata": {
        "id": "x5qmAS-ZI6Il"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/AtiNeu Project/Data/MRI/Brain_Data_Organised/Train'\n",
        "test_dir = '/content/drive/MyDrive/AtiNeu Project/Data/MRI/Brain_Data_Organised/Test'"
      ],
      "metadata": {
        "id": "poSLfq6SIMky"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (650,650)\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "QQtezZL6Jbyt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    seed = 123,\n",
        "    image_size=input_shape,\n",
        "    batch_size = batch_size,\n",
        "    #color_mode = 'grayscale'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2sIPVUVINkY",
        "outputId": "95eb1cb3-3808-494f-cc08-7eb7bc463071"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2251 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed = 123,\n",
        "    image_size = input_shape,\n",
        "    batch_size = batch_size,\n",
        "    #color_mode = 'grayscale'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I_U9R8pIPog",
        "outputId": "9be6027c-e276-4645-afb7-5771b90bf77a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "t0yjQnoYJ9NP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x,y: (normalization_layer(x),y))\n",
        "image_batch = labels_batch = next(iter(normalized_ds))\n",
        "first_img = image_batch[0]\n",
        "print(np.min(first_img),np.max(first_img))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfJMku2BKISw",
        "outputId": "614fd2db-8ca0-4499-cf38-488de6ee3bf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "test_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "Ezxt4bXFKUJm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16,ResNet50\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "metadata": {
        "id": "94NO69AkLWVa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IV3_base_model = InceptionV3(\n",
        "    input_shape = (650,650,3),\n",
        "    weights = 'imagenet',\n",
        "    include_top = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv-sX1s0Lfyk",
        "outputId": "5133932c-1037-4dbd-deaa-9d52703ee741"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze  the first 10 layers\n",
        "for layer in IV3_base_model.layers[:10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = IV3_base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512,activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(2,activation='sigmoid')(x)\n",
        "\n",
        "model1 = Model(inputs = IV3_base_model.inputs, outputs = predictions)"
      ],
      "metadata": {
        "id": "eGJvIJ5ZMOLc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_base_model = VGG16(\n",
        "    input_shape = (650,650,3),\n",
        "    weights = 'imagenet',\n",
        "    include_top = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcuTd81ZPKVk",
        "outputId": "08160888-c365-4abb-f313-a44981fe85e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in VGG16_base_model.layers[:10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = VGG16_base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512,activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(2,activation='sigmoid')(x)\n",
        "\n",
        "model2 = Model(inputs = VGG16_base_model.inputs, outputs = predictions)"
      ],
      "metadata": {
        "id": "XXvi2uEdPs9D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "Vl0vVWpfQR5a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint to save best model per epoch\n",
        "\n",
        "model_filepath = '/content/drive/MyDrive/AtiNeu Project/model-{epoch:02d} - {val_accuracy: .4f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath = model_filepath,\n",
        "    monitor = 'val_accuracy',\n",
        "    mode = 'max',\n",
        "    save_best_only = True,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "JnAK9bqrQkCE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compilations of models"
      ],
      "metadata": {
        "id": "kntfmW0XRL0T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x6T4aV53RSYR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VPkGmsYrReaR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(\n",
        "    train_ds,\n",
        "    validation_data = test_ds,\n",
        "    epochs = 5,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "cWLO_-juSORS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ff746d-17ae-4d70-fc56-53ea70024426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  import gc\n",
        "#  gc.collect()"
      ],
      "metadata": {
        "id": "dPp_9JxCW9-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# acc = history1.history['accuracy']\n",
        "# val_acc = history1.history['val_accuracy']\n",
        "# loss = hitory1.history['loss']\n",
        "# val_loss = history1.history['val_loss']\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "\n",
        "# plt.plot(epochs,acc,'r',label='Train Acc')\n",
        "# plt.plot(epochs,acc,'b',label='Val Acc')\n",
        "# plt.title(\"Training & Validation Accuracy\")\n",
        "# plt.legend()\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs,loss,'r',label='Train Loss')\n",
        "# plt.plot(epochs,acc,'b',label='Val Loss')\n",
        "# plt.title(\"Training & Validation Loss\")\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "FhutGVO-FaWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history2 = model2.fit(\n",
        "#     train_ds,\n",
        "#     validation_data = test_ds,\n",
        "#     epochs = 5,\n",
        "#     callbacks=[checkpoint]\n",
        "# )"
      ],
      "metadata": {
        "id": "clacwdCnF-jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# acc = history2.history['accuracy']\n",
        "# val_acc = history2.history['val_accuracy']\n",
        "# loss = hitory2.history['loss']\n",
        "# val_loss = history2.history['val_loss']\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "\n",
        "# plt.plot(epochs,acc,'r',label='Train Acc')\n",
        "# plt.plot(epochs,acc,'b',label='Val Acc')\n",
        "# plt.title(\"Training & Validation Accuracy\")\n",
        "# plt.legend()\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs,loss,'r',label='Train Loss')\n",
        "# plt.plot(epochs,acc,'b',label='Val Loss')\n",
        "# plt.title(\"Training & Validation Loss\")\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "Y-qzzNavGDDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining Model"
      ],
      "metadata": {
        "id": "RGzJo1ObGXim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input,Average"
      ],
      "metadata": {
        "id": "x8oVdz7DGOFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1 = load_model('/content/drive/MyDrive/model-01-0.9044.hdf5')\n",
        "# model_1 = Model(Input=model_1.inputs,\n",
        "#                 output=model_1.outputs,\n",
        "#                 name='name_of_model_1')"
      ],
      "metadata": {
        "id": "9tt7LOmZGdzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2 = load_model('/content/drive/MyDrive/model-04-0.0156.hdf5')\n",
        "# model_2 = Model(Input=model_2.inputs,\n",
        "#                 output=model_2.outputs,\n",
        "#                 name='name_of_model_2')"
      ],
      "metadata": {
        "id": "RTZYp3ItHl0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# models = [model_1,model_2]\n",
        "# model_input = Input(Shape=(224,224,3))\n",
        "# model_outputs = [model(model_input) for model in models]\n",
        "# ensemble_output = Average()(model_outputs)\n",
        "# ensemble_model = Model(inputs=model_input,outputs=ensemble_outputs,name='ensemble')"
      ],
      "metadata": {
        "id": "MV7TiK5dHuNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensemble_model = model.compile(optimizer='adam',loss=tf.keras.lossed.SparseCategoricalCrossentropy(from_logits=False),\n",
        "#                                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0WvDFbeRIQws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = ensemble_model.fit(\n",
        "#     train_ds,\n",
        "#     validation_data = test_ds,\n",
        "#     epochs=5\n",
        "# )"
      ],
      "metadata": {
        "id": "UR97raWrIjN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "# loss = hitory.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "\n",
        "# plt.plot(epochs,acc,'r',label='Train Acc')\n",
        "# plt.plot(epochs,acc,'b',label='Val Acc')\n",
        "# plt.title(\"Training & Validation Accuracy\")\n",
        "# plt.legend()\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs,loss,'r',label='Train Loss')\n",
        "# plt.plot(epochs,acc,'b',label='Val Loss')\n",
        "# plt.title(\"Training & Validation Loss\")\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "5GFn6MgtJZ3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMwpVMhCJgz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}